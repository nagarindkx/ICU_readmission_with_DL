{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9344a4d8-0c35-4c55-ad6a-d94d5f617109",
   "metadata": {},
   "source": [
    "# Production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf7b945-9554-46d6-a3cd-06d3bd515f41",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c182d4d8-ba36-4d93-b4c4-0ea8ade2a3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf # type: ignore\n",
    "# tf.compat.v1.disable_v2_behavior()\n",
    "# import tensorflow_decision_forests as tfdf\n",
    "import pandas as pd # type: ignore\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "from sklearn.model_selection import (train_test_split, cross_val_score,\n",
    "                                     KFold,ShuffleSplit)\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras import backend as K\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import pickle\n",
    "import time, datetime\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "# sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "# K.set_session(sess)\n",
    "\n",
    "# tf.config.list_logical_devices('GPU')\n",
    "grand_start=time.time()\n",
    "SEED=7\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "seed(SEED)\n",
    "random_state=SEED\n",
    "from tensorflow.keras import initializers\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d04a644-206a-4d38-8a64-7e90c322acf3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204bfdf2-6f97-4363-88fc-e19569df605a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CASE_DF2=pd.read_feather(f'/path/to/CASE_DF2.feather')\n",
    "CONTROL_DF2=pd.read_feather(f'/path/to/CONTROL_DF2.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec79aa3-e288-4471-a687-68f52df3883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CASE_DF2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b802a4f6-0a27-48ec-8447-ffc80742258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTROL_DF2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ecad9a-77eb-4c35-803c-9d855b01bbfd",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf6541f-a978-4bfc-a93f-2019b7f766fa",
   "metadata": {},
   "source": [
    "### n_1, n_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0cf3aa-3e18-4fd1-9084-fd65178b335d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_1=CASE_DF2.stay_id.nunique()\n",
    "n_0=CONTROL_DF2.stay_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57bb3a5-2aa6-488d-8cbc-2c4fcd82cc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_1,n_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0eb902-4735-4c02-9515-905be44f685e",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1c893e-79b8-491f-bc71-914466fc762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TS=pd.concat([CASE_DF2,CONTROL_DF2],axis=0)\n",
    "\n",
    "X=np.concatenate((CASE_DF2.stay_id.unique(), CONTROL_DF2.stay_id.unique()))\n",
    "y=[int(i) for i in np.concatenate((np.ones(n_1),np.zeros(n_0)))]\n",
    "\n",
    "X_train_all, X_test, y_train_all, y_test=train_test_split(X,y                                                  \n",
    "                                                  ,test_size=0.3\n",
    "                                                  ,random_state=random_state\n",
    "                                                  ,shuffle=True\n",
    "                                                 )\n",
    "X_train, X_val, y_train, y_val=train_test_split(X_train_all,y_train_all\n",
    "                                                  ,test_size=0.3\n",
    "                                                  ,random_state=random_state\n",
    "                                                  ,shuffle=True\n",
    "                                                 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ded1b26-b059-4b90-ad85-c940452eaeab",
   "metadata": {},
   "source": [
    "#### DATA เอาไว้ compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba4a491-2c0a-4ba7-856c-0c39e0fca81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA=pd.DataFrame(np.vstack((X,np.array(y))).transpose(),columns=['stay_id','y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d8b5bd-4083-483d-9590-87a3c98d734c",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edde034-7572-4e05-91ae-f83920ed0254",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_columns=[\n",
    "       'HR',\n",
    "       'Non Invasive Blood Pressure systolic',\n",
    "       'Non Invasive Blood Pressure mean', 'RR', 'Arterial O2 pressure',\n",
    "       'Arterial CO2 Pressure', 'O2 saturation pulseoxymetry',\n",
    "       'Hematocrit (serum)', 'WBC', 'Creatinine (serum)', 'Glucose (serum)',\n",
    "       'Sodium (serum)', 'TemperatureF', 'PH (Arterial)',\n",
    "       'Inspired O2 Fraction', 'BUN', 'Total Bilirubin',\n",
    "       'Potassium (serum)', 'HCO3 (serum)', 'Albumin', 'UrineVolumeOut',\n",
    "       'GCS',\n",
    "       ]\n",
    "\n",
    "static_columns=[\n",
    "       'anchor_age',\n",
    "       'G_01',\n",
    "       'G_02', 'G_03', 'G_04', 'G_05', 'G_06', 'G_07', 'G_08', 'G_09', 'G_10',\n",
    "       'G_11', 'G_12', 'G_13', 'G_14', 'G_15', 'G_17', 'G_18', 'G_19', 'G_20',\n",
    "       'G_21', 'count_diags'\n",
    "]\n",
    "\n",
    "NEWS_columns=[\n",
    "        'HR','TemperatureF','RR','Non Invasive Blood Pressure systolic','O2 saturation pulseoxymetry',\n",
    "]\n",
    "\n",
    "OASIS_columns=[\n",
    "        'HR','TemperatureF','GCS','UrineVolumeOut','RR','Non Invasive Blood Pressure mean'\n",
    "]\n",
    "\n",
    "SAP_columns=[\n",
    "        'HR','TemperatureF','GCS','UrineVolumeOut','Non Invasive Blood Pressure systolic',\n",
    "        'BUN','Inspired O2 Fraction','HCO3 (serum)','Arterial O2 pressure',\n",
    "        'Potassium (serum)','Sodium (serum)','Total Bilirubin','WBC',\n",
    "]\n",
    "\n",
    "APACHE_columns=[\n",
    "        'HR','TemperatureF','GCS','UrineVolumeOut','RR','Non Invasive Blood Pressure mean',\n",
    "        'Albumin','BUN','Creatinine (serum)','Inspired O2 Fraction','Glucose (serum)','Hematocrit (serum)',        \n",
    "        'Arterial CO2 Pressure','PH (Arterial)','Arterial O2 pressure',\n",
    "        'Sodium (serum)','Total Bilirubin','WBC',\n",
    "]\n",
    "\n",
    "ALLcommon_columns=[\n",
    "        'HR','TemperatureF','GCS','UrineVolumeOut','RR',\n",
    "]\n",
    "\n",
    "ALLunion_columns=ts_columns\n",
    "\n",
    "#### เอา 'Total Bilirubin','Arterial O2 pressure','BUN', ออก --> AUC เหลือ 0.85\n",
    "\n",
    "\n",
    "# static_columns=[\n",
    "#        'anchor_age','count_diags'\n",
    "# ]\n",
    "\n",
    "_ts_columns=ts_columns\n",
    "# _ts_columns=NEWS_columns\n",
    "_static_columns=static_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e1169a-90f1-4802-8a77-43cbba0f2619",
   "metadata": {},
   "source": [
    "# Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd00abd1-743f-4679-b139-4518a6bd8975",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TS/STATIC\n",
    "\"\"\"\n",
    "#### TRAIN ALL ####\n",
    "_x_train_all_ts=None\n",
    "_y_train_all=None\n",
    "for i,g in TS[TS['stay_id'].isin(X_train_all)].groupby('stay_id'):\n",
    "    _g=g.sort_values('hourfromouttime',ascending=True)[_ts_columns].values\n",
    "    if _x_train_all_ts is None:\n",
    "        _x_train_all_ts=[[i,_g]]\n",
    "    else:\n",
    "        _x_train_all_ts=np.append(_x_train_all_ts,[[i,_g]], axis=0)\n",
    "    \n",
    "    _tmp_y=DATA.query(f'stay_id=={i}').y.values[0].astype(int)\n",
    "    if _y_train_all is None:\n",
    "        _y_train_all=[[i,_tmp_y]]\n",
    "    else:\n",
    "        _y_train_all=np.append(_y_train_all,[[i,_tmp_y]], axis=0)\n",
    "\n",
    "print('_x_train_all_ts')\n",
    "\n",
    "\n",
    "#### TRAIN ####\n",
    "_x_train_ts=None\n",
    "_y_train=None\n",
    "for i,g in TS[TS['stay_id'].isin(X_train)].groupby('stay_id'):\n",
    "    _g=g.sort_values('hourfromouttime',ascending=True)[_ts_columns].values\n",
    "    if _x_train_ts is None:\n",
    "        _x_train_ts=[[i,_g]]\n",
    "    else:\n",
    "        _x_train_ts=np.append(_x_train_ts,[[i,_g]], axis=0)\n",
    "\n",
    "    _tmp_y=DATA.query(f'stay_id=={i}').y.values[0].astype(int)\n",
    "    if _y_train is None:\n",
    "        _y_train=[[i,_tmp_y]]\n",
    "    else:\n",
    "        _y_train=np.append(_y_train,[[i,_tmp_y]], axis=0)\n",
    "print('_x_train_ts')\n",
    "\n",
    "#### VALIDATE ####\n",
    "_x_val_ts=None\n",
    "_y_val=None\n",
    "for i,g in TS[TS['stay_id'].isin(X_val)].groupby('stay_id'):\n",
    "    _g=g.sort_values('hourfromouttime',ascending=True)[_ts_columns].values\n",
    "    if _x_val_ts is None:\n",
    "        _x_val_ts=[[i,_g]]\n",
    "    else:\n",
    "        _x_val_ts=np.append(_x_val_ts,[[i,_g]], axis=0)\n",
    "\n",
    "    _tmp_y=DATA.query(f'stay_id=={i}').y.values[0].astype(int)\n",
    "    if _y_val is None:\n",
    "        _y_val=[[i,_tmp_y]]\n",
    "    else:\n",
    "        _y_val=np.append(_y_val,[[i,_tmp_y]], axis=0)\n",
    "        \n",
    "print('_x_val_ts')\n",
    "\n",
    "#### TEST ####\n",
    "_x_predict_ts=None\n",
    "_y_predict=None\n",
    "for i,g in TS[TS['stay_id'].isin(X_test)].groupby('stay_id'):\n",
    "    _g=g.sort_values('hourfromouttime',ascending=True)[_ts_columns].values\n",
    "    if _x_predict_ts is None:\n",
    "        _x_predict_ts=[[i,_g]]\n",
    "    else:\n",
    "        _x_predict_ts=np.append(_x_predict_ts,[[i,_g]], axis=0)\n",
    "        \n",
    "    _tmp_y=DATA.query(f'stay_id=={i}').y.values[0].astype(int)\n",
    "    if _y_predict is None:\n",
    "        _y_predict=[[i,_tmp_y]]\n",
    "    else:\n",
    "        _y_predict=np.append(_y_predict,[[i,_tmp_y]], axis=0)\n",
    "print('_x_predict_ts')\n",
    "\n",
    "#### CONSTANT ####\n",
    "n_ts_columns=len(_ts_columns)\n",
    "n_static_columns=len(_static_columns)\n",
    "print(f\"n_ts_columns:{n_ts_columns}, n_static_columns:{n_static_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477aa1af-7b62-46f4-a4a1-81a1e0143da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_x_train_all_ts_df=pd.DataFrame(_x_train_all_ts,columns=['stay_id','data'])\n",
    "_x_train_ts_df=pd.DataFrame(_x_train_ts,columns=['stay_id','data'])\n",
    "_x_val_ts_df=pd.DataFrame(_x_val_ts,columns=['stay_id','data'])\n",
    "_x_predict_ts_df=pd.DataFrame(_x_predict_ts,columns=['stay_id','data'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8d28e7-a645-4b06-b179-17e71d4db6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "_y_train_all_df=pd.DataFrame(_y_train_all,columns=['stay_id','y'])\n",
    "_y_train_df=pd.DataFrame(_y_train,columns=['stay_id','y'])\n",
    "_y_val_df=pd.DataFrame(_y_val,columns=['stay_id','y'])\n",
    "_y_predict_df=pd.DataFrame(_y_predict,columns=['stay_id','y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fcd83d-0fde-4aa1-9fba-eae4d7afdd98",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc3eb53-bfeb-46bb-87cc-8e50d34e20c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_n=np.array([i[1] for i in _x_train_all_ts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eb3276-76ec-41f5-9cd0-98918e187e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_ts = StandardScaler()\n",
    "scaler_ts.fit(_n.reshape(_n.shape[0]*_n.shape[1],_n.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173ad1be-1514-4af1-a393-870371dc2ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save StandardScaler\n",
    "f=open('_model/scaler_ts.pickle','wb')\n",
    "pickle.dump(scaler_ts,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fe9ab942-1d4f-498d-8781-f9804b2646b7",
   "metadata": {},
   "source": [
    "_y_train_all_df=pd.DataFrame(_y_train_all,columns=['stay_id','y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d2f3a8-8601-4e7e-b039-dbd9214e976f",
   "metadata": {},
   "source": [
    "### Scale DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55434bfe-9bd7-4f50-96fc-54f86b3841c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_x_train_all_ts_df['data_scale']=None\n",
    "_x_train_ts_df['data_scale']=None\n",
    "_x_val_ts_df['data_scale']=None\n",
    "_x_predict_ts_df['data_scale']=None\n",
    "\n",
    "for i,r  in _x_train_all_ts_df.iterrows():\n",
    "    r['data_scale']=scaler_ts.transform(r['data'])\n",
    "for i,r  in _x_train_ts_df.iterrows():\n",
    "    r['data_scale']=scaler_ts.transform(r['data'])\n",
    "for i,r  in _x_val_ts_df.iterrows():\n",
    "    r['data_scale']=scaler_ts.transform(r['data'])\n",
    "for i,r  in _x_predict_ts_df.iterrows():\n",
    "    r['data_scale']=scaler_ts.transform(r['data'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fa0d35-b8fa-480c-945f-3ba018abe63f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Save Train_all/train/val/predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cea0317-41d1-4724-955c-422560e32c20",
   "metadata": {},
   "source": [
    "## Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4019c4d5-dd1e-4833-9eef-32d8e6c83d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL='PROD'\n",
    "SERIAL='003'\n",
    "epochs=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e6b07e-c873-4230-a57e-bc47a18cb587",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params={}\n",
    "models=['dense','rnn','conv1d','lstm','gru']\n",
    "feature_set=['NEWS','OASIS','SAP','APACHE','ALLcommon','ALLunion']\n",
    "observations=[72,48,24,12,6]\n",
    "\n",
    "feature_set_cols={}\n",
    "feature_set_cols['NEWS']=len(NEWS_columns)\n",
    "feature_set_cols['OASIS']=len(OASIS_columns)\n",
    "feature_set_cols['SAP']=len(SAP_columns)\n",
    "feature_set_cols['APACHE']=len(APACHE_columns)\n",
    "feature_set_cols['ALLcommon']=len(ALLcommon_columns)\n",
    "feature_set_cols['ALLunion']=len(ALLunion_columns)\n",
    "\n",
    "for i in models:\n",
    "    for j in feature_set:\n",
    "        for k in observations:\n",
    "            hyper_params[f'{i}_{j}_{k}']={                \n",
    "                'model_arch': f'{i}',\n",
    "                'feature_set': f'{j}',\n",
    "                'observation': k,\n",
    "                'cols': feature_set_cols[j]\n",
    "                \n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6a6a3d-7a4e-4bfc-a5a8-fb23f4047e20",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2761f938-6dbe-4aa2-b97f-9a47defdf95b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2849e0b2-21b3-4eb4-aec7-39e85d64e480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    print(f'len(y_true): {len(y_true)}, len(y_pred): {len(y_pred)}')\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    #classes = classes[unique_labels(y_true, y_pred)]\n",
    "    nm=\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        nm = \"Norm\"\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        nm = \"withoutNorm\"\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm.round(2))\n",
    "    cm=np.flip(np.flip(cm,-1),0)\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7c39cf-e164-4d4c-8d43-827a69a43110",
   "metadata": {},
   "source": [
    "### AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5590dca8-3619-43d1-8a59-22e178ca1ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def auroc(model, _y_predict, y_hat):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(_y_predict, y_hat)\n",
    "    auc_keras=metrics.auc(fpr, tpr)\n",
    "    acc_per_fold.append(auc_keras)\n",
    "    print(f\"auc_keras: {auc_keras:.4f}\")\n",
    "    # calculate the g-mean for each threshold\n",
    "    gmeans = np.sqrt(tpr * (1-fpr))\n",
    "    J=tpr-fpr\n",
    "    # locate the index of the largest g-mean\n",
    "    ix = np.argmax(gmeans)\n",
    "    ixJ= np.argmax(J)\n",
    "    plt.figure(1, figsize=(5,5))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr, tpr, label=f'{model.name} (area = {auc_keras:.4f})')\n",
    "    plt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Youden\\'s index=%.2f' % (thresholds[ixJ]))\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title(f'ROC curve - {folder} MIMIC-IV')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    plt.savefig(f'{MODEL}/{model.name}.png')\n",
    "    now=datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")    \n",
    "    logdata=f'{now},{model.name},{auc_keras:.4f}'\n",
    "\n",
    "    print(f'thresholds: {thresholds[ixJ]:.4f}')\n",
    "    y_p = [ 0 if i <=thresholds[ixJ] else 1 for i in y_hat ]\n",
    "    # plot_confusion_matrix(y_test, y_p, classes=(0,1), normalize=True, title=f\"{model.name}\")\n",
    "    plot_confusion_matrix(_y_predict, y_p, classes=(0,1), normalize=True, title=f\"{model.name}\")\n",
    "    return auc_keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08e2228-699b-44c8-8d90-48ff39b1fb8d",
   "metadata": {},
   "source": [
    "## Other settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d37b86-6966-4fc7-ab36-d7953e52a412",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Imbalance dataset\n",
    "\"\"\"\n",
    "neg, pos = np.bincount(y)\n",
    "total = neg + pos\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))\n",
    "initial_bias = np.log([pos/neg])\n",
    "\n",
    "weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "print(class_weight)\n",
    "print(f\"initial_bias: {initial_bias}\")\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))\n",
    "\n",
    "\"\"\"\n",
    "เก็บค่า\n",
    "\"\"\"\n",
    "from IPython.display import clear_output\n",
    "acc_per_fold=[]\n",
    "loss_per_fold = []\n",
    "model_fold=[]\n",
    "score_fold=[]\n",
    "\n",
    "\"\"\"\n",
    "Metrics\n",
    "\"\"\"\n",
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.TruePositives(name='tp'),\n",
    "      tf.keras.metrics.FalsePositives(name='fp'),\n",
    "      tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "      tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),\n",
    "      tf.keras.metrics.AUC(name='auc'), \n",
    "      tf.keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "Kernel Initializer\n",
    "\"\"\"\n",
    "kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.01, seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43704b7-2170-400b-92e4-d58bce7d07e3",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc54a45f-52b0-4c37-9d56-1c41e9273088",
   "metadata": {},
   "source": [
    "### dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e06ec1-452b-4bd0-8e4f-45da82acf663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_dense(param,fold=0,debug=True):\n",
    "\n",
    "    model_arch=param['model_arch']\n",
    "    feature_set=param['feature_set']\n",
    "    observation=param['observation']\n",
    "    rows=observation\n",
    "    cols=param['cols']\n",
    "\n",
    "    inputs=tf.keras.layers.Input(shape=(rows,cols)\n",
    "                                 , name='input')\n",
    "    flattern1=tf.keras.layers.Flatten(name='flattern1')(inputs)    \n",
    "    ts1=tf.keras.layers.Dense(units=(rows*cols)\n",
    "                               , kernel_initializer=kernel_initializer\n",
    "                               , name='dense_1')(flattern1)\n",
    "    dropout1=tf.keras.layers.Dropout(0.8)(ts1)\n",
    "    ts2=tf.keras.layers.Dense(units=(rows*cols)\n",
    "                               , kernel_initializer=kernel_initializer\n",
    "                               , name='dense_2')(dropout1)\n",
    "\n",
    "    outputs=tf.keras.layers.Dense(1\n",
    "                                  , kernel_initializer=kernel_initializer\n",
    "                                  , activation='sigmoid'\n",
    "                                  , name='output')(ts2)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model._name=f'{model_arch}_{feature_set}_{observation}_fold{fold}'\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy'\n",
    "        ,metrics=[METRICS]\n",
    "    )\n",
    "    \n",
    "    if debug:\n",
    "        model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e7a754-f510-4a23-9ff1-082c77429548",
   "metadata": {},
   "source": [
    "### conv1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b0ebce-5c24-4ebe-a719-c591de9e3c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_conv1d(param,fold=0,debug=True):\n",
    "    model_arch=param['model_arch']\n",
    "    feature_set=param['feature_set']\n",
    "    observation=param['observation']\n",
    "    rows=observation\n",
    "    cols=param['cols']\n",
    "\n",
    "    inputs=tf.keras.layers.Input(shape=(rows,cols))\n",
    "\n",
    "    ts1=tf.keras.layers.Conv1D(filters=1\n",
    "                               , kernel_size=round(rows/2)\n",
    "                               , kernel_initializer=kernel_initializer\n",
    "                               , name='conv1d_1')(inputs)\n",
    "    dropout1=tf.keras.layers.Dropout(0.8)(ts1)\n",
    "    ts2=tf.keras.layers.Conv1D(filters=1\n",
    "                               , kernel_size=round(rows/2)\n",
    "                               , kernel_initializer=kernel_initializer\n",
    "                               , name='conv1d_2')(dropout1)\n",
    "\n",
    "\n",
    "    flattern1=tf.keras.layers.Flatten(name='flattern_1')(ts2)\n",
    "    outputs=tf.keras.layers.Dense(1\n",
    "                                  , activation='sigmoid'\n",
    "                                  , kernel_initializer=kernel_initializer\n",
    "                                  , name='output')(flattern1)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model._name=f'{model_arch}_{feature_set}_{observation}_fold{fold}'\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy'\n",
    "        ,metrics=[METRICS]\n",
    "    )\n",
    "    \n",
    "    if debug:\n",
    "        model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cc61b9-6fc7-4366-9570-586a3c41168b",
   "metadata": {},
   "source": [
    "### rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca6a1fe-a71e-4fc7-b0f1-b15b531c2d99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_rnn(param,fold=0,debug=True):\n",
    "    model_arch=param['model_arch']\n",
    "    feature_set=param['feature_set']\n",
    "    observation=param['observation']\n",
    "    rows=observation\n",
    "    cols=param['cols']\n",
    "\n",
    "    inputs=tf.keras.layers.Input(shape=(rows,cols))\n",
    "\n",
    "    ts1=tf.keras.layers.SimpleRNN(\n",
    "                                 units=round(rows/2)\n",
    "                               , dropout=0.8\n",
    "                               , return_sequences=True\n",
    "                               , kernel_initializer=kernel_initializer\n",
    "                               , name='rnn_1')(inputs)\n",
    "    ts2=tf.keras.layers.SimpleRNN(\n",
    "                                 units=round(rows/4)\n",
    "                               , return_sequences=False\n",
    "                               , kernel_initializer=kernel_initializer\n",
    "                               , name='rnn_2')(ts1)\n",
    "    outputs=tf.keras.layers.Dense(1\n",
    "                                  , kernel_initializer=kernel_initializer\n",
    "                                  , activation='sigmoid'\n",
    "                                  , name='output')(ts2)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model._name=f'{model_arch}_{feature_set}_{observation}_fold{fold}'\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy'\n",
    "        ,metrics=[METRICS]\n",
    "    )\n",
    "    \n",
    "    if debug:\n",
    "        model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0164247-8304-4d81-b23b-78a57113af64",
   "metadata": {},
   "source": [
    "### lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a3287c-7f5b-4925-a2b2-0af71ec68d1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_lstm(param,fold=0,debug=True):\n",
    "    model_arch=param['model_arch']\n",
    "    feature_set=param['feature_set']\n",
    "    observation=param['observation']\n",
    "    rows=observation\n",
    "    cols=param['cols']\n",
    "\n",
    "    inputs=tf.keras.layers.Input(shape=(rows,cols))\n",
    "\n",
    "    ts1=tf.keras.layers.LSTM(\n",
    "                                 units=round(rows/2)\n",
    "                               , dropout=0.8\n",
    "                               , return_sequences=True\n",
    "                               , kernel_initializer=kernel_initializer\n",
    "                               , name='lstm_1')(inputs)\n",
    "    ts2=tf.keras.layers.LSTM(\n",
    "                                 units=round(rows/4)\n",
    "                               , return_sequences=False\n",
    "                               , kernel_initializer=kernel_initializer\n",
    "                               , name='lstm_2')(ts1)\n",
    "\n",
    "    outputs=tf.keras.layers.Dense(1\n",
    "                                  , kernel_initializer=kernel_initializer\n",
    "                                  , activation='sigmoid'\n",
    "                                  , name='output')(ts2)\n",
    "    \n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model._name=f'{model_arch}_{feature_set}_{observation}_fold{fold}'\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy'\n",
    "        ,metrics=[METRICS]\n",
    "    )\n",
    "    \n",
    "    if debug:\n",
    "        model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d924c2e5-b381-4a4b-b661-c55dd4a973a1",
   "metadata": {},
   "source": [
    "### gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c1b1bd-ff09-4535-b13a-297aeb0a9684",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_gru(param,fold=0,debug=True):\n",
    "    model_arch=param['model_arch']\n",
    "    feature_set=param['feature_set']\n",
    "    observation=param['observation']\n",
    "    rows=observation\n",
    "    cols=param['cols']\n",
    "\n",
    "    inputs=tf.keras.layers.Input(shape=(rows,cols))\n",
    "\n",
    "    ts1=tf.keras.layers.GRU(\n",
    "                                 units=round(rows/2)\n",
    "                               , dropout=0.8\n",
    "                               , return_sequences=True\n",
    "                               , kernel_initializer=kernel_initializer\n",
    "                               , name='gru_1')(inputs)\n",
    "    ts2=tf.keras.layers.GRU(\n",
    "                                 units=round(rows/4)\n",
    "                               , return_sequences=False\n",
    "                                , kernel_initializer=kernel_initializer\n",
    "                               , name='gru_2')(ts1)\n",
    "    outputs=tf.keras.layers.Dense(1\n",
    "                                  , kernel_initializer=kernel_initializer\n",
    "                                  , activation='sigmoid'\n",
    "                                  , name='output')(ts2)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model._name=f'{model_arch}_{feature_set}_{observation}_fold{fold}'\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy'\n",
    "        ,metrics=[METRICS]\n",
    "    )\n",
    "    \n",
    "    if debug:\n",
    "        model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "97f9327e-dd39-4f7f-8e23-5b4094c43ca5",
   "metadata": {},
   "source": [
    "print(hyper_params['rnnALL_union72'])\n",
    "model_rnn(hyper_params['rnnALL_union72'],debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac661e6-beae-4e74-a8ac-9ef0d6fe3f88",
   "metadata": {},
   "source": [
    "## System testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04ce901-8d16-4d83-af13-b20d7146611f",
   "metadata": {},
   "source": [
    "### def get_datascale(param, data_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d17f44-ebdd-4ca9-9aa7-5248e94782be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datascale(param, data_scale):\n",
    "    result=np.vstack(\n",
    "        \n",
    "            [\n",
    "                data_scale[0:param['observation'],j] # rows\n",
    "                for j in [ts_columns.index(i) for i in eval(f\"{param['feature_set']}_columns\")] # cols\n",
    "            ]\n",
    "        \n",
    "        ).transpose()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2c2e4a-9006-443a-9261-921eb528bed5",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de791fce-ce35-4f4b-8e7b-d9b4d17dd22d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CV_X = np.array([ i.tolist() for i in _x_train_ts_df.data_scale])\n",
    "CV_Predict_X=np.array([ i.tolist() for i in _x_predict_ts_df.data_scale])\n",
    "CV_y = np.array(_y_train_df.y.values.tolist())\n",
    "CV_Predict_y=np.array(_y_predict_df.y.values)\n",
    "\n",
    "\n",
    "num_folds=5\n",
    "kf = KFold(n_splits=num_folds, shuffle=False)\n",
    "\n",
    "scores_fold={}\n",
    "\n",
    "n_fold=1\n",
    "for train_index, test_index in kf.split(CV_X):\n",
    "        clear_output(wait=True)\n",
    "        CV_X_train, CV_X_test = CV_X[train_index], CV_X[test_index]\n",
    "        CV_y_train, CV_y_test = CV_y[train_index], CV_y[test_index]\n",
    "        for i in hyper_params:\n",
    "            param=hyper_params[i]\n",
    "            model=eval(f\"model_{param['model_arch']}(param,fold={n_fold},debug=False)\")\n",
    "            logdir = os.path.join(f\"{MODEL}\", f\"{model._name}\")\n",
    "            tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "            history=model.fit(                       \n",
    "                x=np.array([ get_datascale(param,i).tolist() \n",
    "                     for i in CV_X_train]),            \n",
    "                y=CV_y_train,\n",
    "                batch_size=100,\n",
    "                verbose=0,\n",
    "                epochs=100,\n",
    "                class_weight=class_weight,\n",
    "                callbacks=[tensorboard_callback],                \n",
    "                validation_data=[np.array([ get_datascale(param,i).tolist() \n",
    "                     for i in CV_X_test]),CV_y_test]\n",
    "            )\n",
    "            scores = model.evaluate(\n",
    "                x=np.array([ get_datascale(param,i).tolist() \n",
    "                     for i in CV_Predict_X]), \n",
    "                y=CV_Predict_y,\n",
    "                batch_size=100,\n",
    "                verbose=0)\n",
    "            scores_fold[model.name]=scores\n",
    "            with open('scores_fold.pickle', 'wb') as handle:\n",
    "                pickle.dump(scores_fold, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                handle.close\n",
    "        n_fold=n_fold+1\n",
    "summary_score=[]\n",
    "for i in scores_fold:\n",
    "    summary_score.append(scores_fold[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1095e1f4-bdcd-48b0-a913-130b18c93b77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_score=[]\n",
    "for i in scores_fold:\n",
    "    summary_score.append([i]+scores_fold[i])\n",
    "summary_score_df=pd.DataFrame(summary_score, columns=['model_name']+model.metrics_names)\n",
    "summary_score_df.auc.describe()\n",
    "summary_score_df.sort_values('auc', ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc530679-7ccc-48b4-b9f1-3a0b33249b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "summary_score_df['observation']=summary_score_df['model_name']\\\n",
    "    .apply(lambda x: re.findall(r'_(\\d{1,2})_fold',x)[0])\n",
    "summary_score_df['model_architecture']=summary_score_df['model_name']\\\n",
    "    .apply(lambda x: re.findall(r'^(.*)_(.*)_(\\d{1,2})_fold',x)[0][0])\n",
    "summary_score_df['feature_set']=summary_score_df['model_name']\\\n",
    "    .apply(lambda x: re.findall(r'^(.*)_(.*)_(\\d{1,2})_fold',x)[0][1])\n",
    "summary_score_df.groupby('observation')['auc'].mean()\\\n",
    "    .reset_index(name='auc_mean')\\\n",
    "    .sort_values('auc_mean', ascending=False)\n",
    "summary_score_df.groupby('model_architecture')['auc'].mean()\\\n",
    "    .reset_index(name='auc_mean')\\\n",
    "    .sort_values('auc_mean', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e5d9a2-d971-4609-9ad6-402cfdf6717d",
   "metadata": {},
   "source": [
    "### summary_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e626ffbe-c651-4b7d-a36d-d27cb2ae73d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_score_df.groupby('feature_set')['auc'].mean()\\\n",
    "    .reset_index(name='auc_mean')\\\n",
    "    .sort_values('auc_mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6382ad6b-c68d-4aa7-81ae-2a3633f2b868",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_score_df\\\n",
    "    .groupby(['model_architecture','feature_set','observation'])['auc']\\\n",
    "    .mean()\\\n",
    "    .reset_index(name='auc_mean')\\\n",
    "    .sort_values('auc_mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3953581b-714b-4947-abc8-339275ea4053",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_observation=summary_score_df.groupby('observation')['auc']\\\n",
    "    .mean().to_frame().reset_index()\\\n",
    "    .sort_values('auc',ascending=False)\\\n",
    "    .iloc[0,0]\n",
    "best_observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cce7aa7-a734-4cbf-b1ab-7367d0e3d39e",
   "metadata": {},
   "source": [
    "### summary_score_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff19fabe-6f69-400e-bf06-c0841bfc7b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_score_df2=summary_score_df\\\n",
    "    .groupby(['model_architecture','feature_set','observation'])['auc']\\\n",
    "    .mean()\\\n",
    "    .reset_index(name='auc_mean')\\\n",
    "    .sort_values('auc_mean', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6b95e7-cdca-46d9-b693-c69e6debbdfc",
   "metadata": {},
   "source": [
    "### summary_score_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c41e696-9c2d-410a-856c-0b215cf7c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_score_df3=pd.merge(\n",
    "    summary_score_df2.groupby('observation')['auc_mean'].max().to_frame().reset_index(),\n",
    "    summary_score_df2\n",
    "    , how = 'left'\n",
    "    , on = ['observation','auc_mean']\n",
    ").astype({'observation':int}).sort_values('observation',ascending=True)\n",
    "\n",
    "summary_score_df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e10d689-c073-4b5a-9e97-a0c25753a8f5",
   "metadata": {},
   "source": [
    "### _selected_hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a37746-7388-46c6-ab4c-6651d9e5fafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "_selected_hp=summary_score_df3\\\n",
    "    .apply( lambda x: f\"{x['model_architecture']}_{x['feature_set']}_{x['observation']}\", axis=1)\\\n",
    "    .values.tolist()\n",
    "\n",
    "_selected_hp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0734686f-9758-4984-b207-6897009abf34",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5db170-06f6-4f4d-83a2-975faa5cde73",
   "metadata": {},
   "source": [
    "### สร้าง hyper_params เฉพาะ ที่จะเอา"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acba85f-3500-4df8-a1f5-45d7cc68196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypyer params แต่ละ observation ที่ให้ AUC สูงสุด\n",
    "_selected_hp=[\n",
    "    # 'lstm_SAP_6',\n",
    "    # 'lstm_APACHE_6',\n",
    "    # 'lstm_SAP_12',    \n",
    "    # 'lstm_SAP_24',\n",
    "    # 'rnn_SAP_48',\n",
    "    # 'gru_SAP_48',\n",
    "    # 'lstm_SAP_72',\n",
    "    # 'rnn_SAP_48',\n",
    "    'rnn_SAP_72',\n",
    "]\n",
    "\n",
    "# print(hyper_params['lstm_SAP_6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd9ba35-45b0-420f-a427-a88b7e5cf9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# เฉพาะใน _selected_hp\n",
    "for hpk in _selected_hp:\n",
    "    hyper_params_key=hpk\n",
    "    model_arch = hyper_params[hyper_params_key]['model_arch']    \n",
    "    model=eval(f\"model_{model_arch}(hyper_params[hyper_params_key],debug=True)\")     \n",
    "    print(hpk, model_arch)\n",
    "\n",
    "    logdir = os.path.join(f\"{MODEL}\", f\"{model._name}\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "    print('Tensorboard')\n",
    "\n",
    "    history=model.fit(            \n",
    "        x=[ get_datascale(hyper_params[hyper_params_key],i).tolist() \n",
    "               for i in _x_train_all_ts_df.data_scale],\n",
    "        y=_y_train_all_df.y.values.tolist(),\n",
    "        batch_size=100,\n",
    "        verbose=0,\n",
    "        epochs=100,\n",
    "        class_weight=class_weight,\n",
    "        callbacks=[tensorboard_callback],\n",
    "        validation_data=[[ get_datascale(hyper_params[hyper_params_key],i).tolist() for i in _x_val_ts_df.data_scale],_y_val_df.y.values.tolist()]\n",
    "    )\n",
    "    model.save(f'model/{hyper_params_key}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f2f89a-8446-4fd0-9ca4-e69bee8f9c0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn import metrics\n",
    "\n",
    "all_predict_fold={}\n",
    "predict_fold={}    \n",
    "for hpk in _selected_hp:\n",
    "    _model=tf.keras.models.load_model(f'model/{hpk}.h5')\n",
    "    _hyper_params_key=hpk\n",
    "    _prediction_result=_model.predict(\n",
    "            [ get_datascale(hyper_params[hpk],i).tolist() \n",
    "             for i in _x_predict_ts_df.data_scale\n",
    "            ]\n",
    "        ).flatten().tolist()\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(_y_predict_df.y.values.tolist(),_prediction_result, pos_label=1)\n",
    "    roc_auc=metrics.auc(fpr, tpr)\n",
    "    print(_hyper_params_key)\n",
    "    predict_fold[_hyper_params_key]={\n",
    "        'fpr':fpr\n",
    "        ,'tpr':tpr\n",
    "        ,'thresholds': thresholds\n",
    "        ,'roc_auc':roc_auc}\n",
    "    \n",
    "def get_auc(item):\n",
    "    auc=item[1]['roc_auc']\n",
    "    return auc\n",
    "sorted_auc=dict(sorted(predict_fold.items(), key=get_auc,reverse=True) )\n",
    "all_predict_fold[list(sorted_auc.keys())[0]]=sorted_auc[list(sorted_auc.keys())[0]]\n",
    "\n",
    "\n",
    "plt.figure(dpi=100)\n",
    "for k in sorted_auc.keys():\n",
    "    # print(sorted_auc[k]['roc_auc'])\n",
    "    fpr=sorted_auc[k]['fpr']\n",
    "    tpr=sorted_auc[k]['tpr']\n",
    "    roc_auc=sorted_auc[k]['roc_auc']    \n",
    "    plt.plot(fpr,tpr,label=f\"{k}, AUC={roc_auc:.2f}\")\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(f'fig/selected_hyperparams.jpg')\n",
    "plt.show()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6670f1d-4972-40e2-8bda-0ead377ea08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_key = list(dict(sorted(all_predict_fold.items(), key=get_auc,reverse=True)).keys())[0]\n",
    "\n",
    "print(best_model_key, f\"{all_predict_fold[best_model_key]['roc_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf50a4d-9d63-4f91-a7bf-822c69c23219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from math import sqrt\n",
    "\n",
    "# def roc_auc_ci(y_true, y_score, positive=1):\n",
    "#     AUC = roc_auc_score(y_true, y_score)\n",
    "# N1=No.of Positive\n",
    "# N2=No.of Negative\n",
    "params={\n",
    "    'AUC': 0,\n",
    "    'N1':0,\n",
    "    'N2':0,\n",
    "}\n",
    "def roc_auc_ci(params=params, positive=1):\n",
    "    AUC = params['AUC']\n",
    "    N1 = params['N1']\n",
    "    N2 = params['N2']\n",
    "    Q1 = AUC / (2 - AUC)\n",
    "    Q2 = 2*AUC**2 / (1 + AUC)\n",
    "    SE_AUC = sqrt((AUC*(1 - AUC) + (N1 - 1)*(Q1 - AUC**2) + (N2 - 1)*(Q2 - AUC**2)) / (N1*N2))\n",
    "    lower = AUC - 1.96*SE_AUC\n",
    "    upper = AUC + 1.96*SE_AUC\n",
    "    if lower < 0:\n",
    "        lower = 0\n",
    "    if upper > 1:\n",
    "        upper = 1\n",
    "    return (f\"({lower:.2f}-{upper:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464e59bb-c401-46b8-ac08-8255f7c44b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "_y_predict_df.groupby(['y']).y.count().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccee1e0-8e88-4e1a-8dfc-237f5a1350b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "    'AUC': all_predict_fold[best_model_key]['roc_auc'],\n",
    "    'N1':80,\n",
    "    'N2':1355,\n",
    "}\n",
    "roc_auc_ci(params=params, positive=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627f86bb-0ad1-4f95-8e06-33496cf3b759",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(sorted(all_predict_fold.items(), key=get_auc,reverse=True)).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43212498-f001-4d3d-bc14-f41fd3771815",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "fpr=all_predict_fold[best_model_key]['fpr']\n",
    "tpr=all_predict_fold[best_model_key]['tpr']\n",
    "thresholds=all_predict_fold[best_model_key]['thresholds']\n",
    "\n",
    "\n",
    "\n",
    "roc_auc=metrics.auc(fpr, tpr)\n",
    "# calculate the g-mean for each threshold\n",
    "gmeans = np.sqrt(tpr * (1-fpr))\n",
    "J=tpr-fpr\n",
    "# locate the index of the largest g-mean\n",
    "ix = np.argmax(gmeans)\n",
    "ixJ= np.argmax(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee41946-99be-4eeb-92ea-cf52227d779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc,f\"{thresholds[ixJ]:.2f}\",ix,ixJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b29c0a-925c-42d6-9a7c-2e1302187edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=100)\n",
    "lw = 2\n",
    "plt.plot(\n",
    "    fpr,\n",
    "    tpr,\n",
    "    color=\"darkorange\",\n",
    "    lw=lw,\n",
    "    label=\"ROC curve (area = %0.2f, thresholds=%0.2f)\" % (roc_auc,thresholds[ixJ] ),\n",
    ")\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(f\"AUROC {best_model_key}\")\n",
    "plt.title(f\"AUROC of RNN with SAP-II at 72 hours\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1519b4b-83b6-4fa7-b86c-ffe70298f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datascale(param, data_scale):\n",
    "    result=np.vstack(\n",
    "        \n",
    "            [\n",
    "                data_scale[0:param['observation'],j] # rows\n",
    "                for j in [ts_columns.index(i) for i in eval(f\"{param['feature_set']}_columns\")] # cols\n",
    "            ]\n",
    "        \n",
    "        ).transpose()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6180a7b6-c621-486f-abf3-71e9ff4e6eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hyper_params[best_model_key])\n",
    "print(SAP_columns)\n",
    "model=tf.keras.models.load_model(f'model/{best_model_key}.h5')\n",
    "final_prediction_result=model.predict([ get_datascale(hyper_params[best_model_key],i).tolist() \n",
    "                                           for i in _x_predict_ts_df.data_scale])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92c2d1a-ccf3-47ad-b9ab-72b24182a263",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_p = [ 0 if i <=thresholds[ixJ] else 1 for i in final_prediction_result ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb80673a-af9e-4978-a487-10974b578107",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_yp=len(y_p)\n",
    "correct_0=0\n",
    "correct_1=0\n",
    "for i in range(l_yp):\n",
    "    if y_p[i]==_y_predict_df.y.values.tolist()[i]:\n",
    "        if y_p[i]==0:\n",
    "            correct_0=correct_0+1\n",
    "        else:\n",
    "            correct_1=correct_1+1\n",
    "print(correct_0, correct_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdaaded-1111-4d49-95b2-937e0713af74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(_y_predict_df.y.values.tolist(),y_p)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4258e4-9f58-4762-9fc7-4c37906a53c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_p,_y_predict_df.y.values.tolist())\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c42084-0676-4987-aae4-3cb560374d1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax=plot_confusion_matrix(_y_predict_df.y.values.tolist()\n",
    "                      ,y_p\n",
    "                      ,classes=(1,0)\n",
    "                      , normalize=True, title=f\"Confusion matrix of the final model (nomalized)\\n\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8b07b67f-5e0a-47fa-9a17-8217dd28b948",
   "metadata": {},
   "source": [
    "np.flip(np.flip(cm,-1),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5e32f3-74f9-4713-bef0-311415dd43a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a2b770-7ecd-44bd-85c8-71d96bcfc0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Parameters\n",
    "# best_model_key='gru_SAP_48'\n",
    "\n",
    "all_params={\n",
    "    'best_model_key': best_model_key,\n",
    "    'hyper_params':hyper_params,\n",
    "    '_x_val_ts_df':_x_val_ts_df,\n",
    "    '_x_train_ts_df':_x_train_ts_df,\n",
    "    '_x_train_all_ts_df':_x_train_all_ts_df,\n",
    "    '_x_predict_ts_df': _x_predict_ts_df,\n",
    "    '_y_train_all_df':_y_train_all_df,\n",
    "    '_y_train_df':_y_train_df,\n",
    "    '_y_val_df':_y_val_df,\n",
    "    '_y_predict_df':_y_predict_df,\n",
    "}\n",
    "with open('./SHAP/all_params.pickle','wb') as handle:\n",
    "    pickle.dump(all_params,handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2f4bca-f2d0-43f6-97b0-2a9b008be637",
   "metadata": {},
   "source": [
    "# !!!! DONE !!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51084b70-36f9-4004-ae4d-f62493273dd0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Go to SHAP.ipynb"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8bb81b95-1c1f-4d23-8364-f845c97308db",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
